<!DOCTYPE html>
<html lang="en-US">
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*       on 2021-06-29T12:15:04+02:00       *-->
<!--*   A recent stable commit (2020-08-09):   *-->
<!--* 98f21740783f166a773df4dc83cab5293ab63a4a *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="robots" content="noindex, nofollow">
</head>
<body>
<h6 xmlns:svg="http://www.w3.org/2000/svg" class="heading"><span class="type">Paragraph</span></h6>
<p>Let us denote by \(\Omega_A\) and \(\Omega_B\) the sets of weights of \(\mathcal V\) and \(\mathcal W\text{.}\) Notice first that by definition of the <a class="xref" data-knowl="./knowl/def-push-forward-grading.html" title="Definition 2.4">push-forward</a>, \(f(\Omega_A) = \Omega_B\) and \(g(\Omega_B) = \Omega_A\text{,}\) so both \(f\) and \(g\) are injective on weights. Moreover, we have for every \(\alpha \in \Omega_A\) and \(\beta \in \Omega_B\) the correspondence</p>
<div xmlns:svg="http://www.w3.org/2000/svg" class="displaymath">
\begin{equation*}
V_\alpha = W_{f(\alpha)} = V_{g(f(\alpha))} \qquad \text{and} \qquad W_\beta = V_{g(\beta)} = W_{f(g(\beta))}.
\end{equation*}
</div>
<p class="continuation">Hence \(f\colon \Omega_A \to \Omega_B \) is a bijection and \(f^{-1} = g\) on \(\Omega_B\text{.}\) Since \(\Omega_A\) and \(\Omega_B\) generate \(A \) and \(B\) as groups, we get that \(f^{-1} = g\) on whole \(B\text{.}\)</p>
<span class="incontext"><a href="section-preliminaries.html#p-37">in-context</a></span>
</body>
</html>
